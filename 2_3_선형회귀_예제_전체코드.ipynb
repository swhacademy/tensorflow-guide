{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2_3_선형회귀_예제 전체코드.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swhacademy/tensorflow-guide/blob/master/2_3_%EC%84%A0%ED%98%95%ED%9A%8C%EA%B7%80_%EC%98%88%EC%A0%9C_%EC%A0%84%EC%B2%B4%EC%BD%94%EB%93%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "2gQtjj1Sxv37",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "outputId": "491f650a-8da8-47cf-c34a-fa9c77fd4ceb"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "tf.set_random_seed(777)  # for reproducibility\n",
        "\n",
        "x_data = [1, 2, 3]\n",
        "y_data = [1, 2, 3]\n",
        "\n",
        "# Try to find values for W and b to compute y_data = W * x_data\n",
        "# We know that W should be 1\n",
        "# But let's use TensorFlow to figure it out\n",
        "W = tf.Variable(tf.random_normal([1]), name=\"weight\")\n",
        "\n",
        "X = tf.placeholder(tf.float32)\n",
        "Y = tf.placeholder(tf.float32)\n",
        "\n",
        "# Our hypothesis for linear model X * W\n",
        "hypothesis = X * W\n",
        "\n",
        "# cost/loss function\n",
        "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
        "\n",
        "# Minimize: Gradient Descent using derivative: W -= learning_rate * derivative\n",
        "learning_rate = 0.1\n",
        "gradient = tf.reduce_mean((W * X - Y) * X)\n",
        "descent = W - learning_rate * gradient\n",
        "update = W.assign(descent)\n",
        "\n",
        "# Launch the graph in a session.\n",
        "with tf.Session() as sess:\n",
        "    # Initializes global variables in the graph.\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "\n",
        "    for step in range(21):\n",
        "        _, cost_val, W_val = sess.run(\n",
        "            [update, cost, W], feed_dict={X: x_data, Y: y_data}\n",
        "        )\n",
        "        print(step, cost_val, W_val)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "0 6.8174477 [1.6446238]\n",
            "1 1.9391857 [1.3437994]\n",
            "2 0.5515905 [1.1833596]\n",
            "3 0.15689684 [1.0977918]\n",
            "4 0.044628453 [1.0521556]\n",
            "5 0.012694317 [1.0278163]\n",
            "6 0.003610816 [1.0148354]\n",
            "7 0.0010270766 [1.0079122]\n",
            "8 0.00029214387 [1.0042198]\n",
            "9 8.309683e-05 [1.0022506]\n",
            "10 2.363606e-05 [1.0012003]\n",
            "11 6.723852e-06 [1.0006402]\n",
            "12 1.912386e-06 [1.0003414]\n",
            "13 5.439676e-07 [1.000182]\n",
            "14 1.5459062e-07 [1.000097]\n",
            "15 4.3941593e-08 [1.0000517]\n",
            "16 1.2491266e-08 [1.0000275]\n",
            "17 3.5321979e-09 [1.0000147]\n",
            "18 9.998237e-10 [1.0000079]\n",
            "19 2.8887825e-10 [1.0000042]\n",
            "20 8.02487e-11 [1.0000023]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}